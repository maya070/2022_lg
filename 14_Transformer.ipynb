{"cells":[{"cell_type":"markdown","metadata":{"id":"8cPNLFZDkUQx"},"source":["Reference: https://www.youtube.com/watch?v=M6adRGJe5cQ&t=180s"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-09-14T05:19:30.097705Z","start_time":"2022-09-14T05:19:30.093725Z"},"id":"io7ityAYc_UU","outputId":"0a7dfa1c-8d9e-486b-b2ef-0349639cd22a"},"outputs":[{"data":{"text/plain":["True"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","torch.cuda.is_available()"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-09-14T05:19:30.527716Z","start_time":"2022-09-14T05:19:30.099117Z"},"id":"LSoqv_9RYR8J"},"outputs":[],"source":["import sys\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.tensorboard import SummaryWriter\n","from torchtext.data.metrics import bleu_score\n","# from torchtext.datasets import Multi30k\n","# from torchtext.data import Field, BucketIterator\n","from torchtext.legacy.datasets import Multi30k\n","from torchtext.legacy.data import Field, BucketIterator\n","import spacy"]},{"cell_type":"markdown","source":["![](https://pytorch.org/tutorials/_images/transformer_architecture.jpg)"],"metadata":{"id":"CtGylpGbdZkp"}},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-09-14T05:19:30.534503Z","start_time":"2022-09-14T05:19:30.529330Z"},"id":"D9BdqeiYc_UW"},"outputs":[],"source":["def translate_sentence(model, sentence, german, english, device, max_length=50):\n","    # Load german tokenizer\n","#     spacy_ger = spacy.load(\"de\")\n","    spacy_ger = spacy.load(\"de_core_news_sm\")\n","\n","    # Create tokens using spacy and everything in lower case (which is what our vocab is)\n","    if type(sentence) == str:\n","        tokens = [token.text.lower() for token in spacy_ger(sentence)]\n","    else:\n","        tokens = [token.lower() for token in sentence]\n","\n","    # Add <SOS> and <EOS> in beginning and end respectively\n","    tokens.insert(0, german.init_token)\n","    tokens.append(german.eos_token)\n","\n","    # Go through each german token and convert to an index\n","    text_to_indices = [german.vocab.stoi[token] for token in tokens]\n","\n","    # Convert to Tensor\n","    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\n","\n","    outputs = [english.vocab.stoi[\"<sos>\"]]\n","    for i in range(max_length):\n","        trg_tensor = torch.LongTensor(outputs).unsqueeze(1).to(device)\n","\n","        with torch.no_grad():\n","            output = model(sentence_tensor, trg_tensor)\n","\n","        best_guess = output.argmax(2)[-1, :].item()\n","        outputs.append(best_guess)\n","\n","        if best_guess == english.vocab.stoi[\"<eos>\"]:\n","            break\n","\n","    translated_sentence = [english.vocab.itos[idx] for idx in outputs]\n","    # remove start token\n","    return translated_sentence[1:]\n","\n","\n","def bleu(data, model, german, english, device):\n","    targets = []\n","    outputs = []\n","\n","    for example in data:\n","        src = vars(example)[\"src\"]\n","        trg = vars(example)[\"trg\"]\n","\n","        prediction = translate_sentence(model, src, german, english, device)\n","        prediction = prediction[:-1]  # remove <eos> token\n","\n","        targets.append([trg])\n","        outputs.append(prediction)\n","\n","    return bleu_score(outputs, targets)\n","\n","\n","def save_checkpoint(state, filename=\"my_checkpoint.pth.tar\"):\n","    print(\"=> Saving checkpoint\")\n","    torch.save(state, filename)\n","\n","\n","def load_checkpoint(checkpoint, model, optimizer):\n","    print(\"=> Loading checkpoint\")\n","    model.load_state_dict(checkpoint[\"state_dict\"])\n","    optimizer.load_state_dict(checkpoint[\"optimizer\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-09-14T05:19:50.235741Z","start_time":"2022-09-14T05:19:30.536339Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":444869,"status":"ok","timestamp":1630041413484,"user":{"displayName":"조영성","photoUrl":"","userId":"06200809104620413861"},"user_tz":-540},"id":"ZvbfpbKxaVP5","outputId":"2faf0de6-405c-4c32-bba5-6629b051377a"},"outputs":[{"name":"stdout","output_type":"stream","text":["downloading training.tar.gz\n"]},{"name":"stderr","output_type":"stream","text":["training.tar.gz: 100%|█████████████████████████████████████████████████████████████████████| 1.21M/1.21M [00:04<00:00, 285kB/s]\n"]},{"name":"stdout","output_type":"stream","text":["downloading validation.tar.gz\n"]},{"name":"stderr","output_type":"stream","text":["validation.tar.gz: 100%|██████████████████████████████████████████████████████████████████| 46.3k/46.3k [00:00<00:00, 60.3kB/s]\n"]},{"name":"stdout","output_type":"stream","text":["downloading mmt_task1_test2016.tar.gz\n"]},{"name":"stderr","output_type":"stream","text":["mmt_task1_test2016.tar.gz: 100%|██████████████████████████████████████████████████████████| 66.2k/66.2k [00:01<00:00, 65.1kB/s]\n"]}],"source":["# spacy_ger = spacy.load(\"de\")\n","# spacy_eng = spacy.load(\"en\")\n","spacy_ger = spacy.load(\"de_core_news_sm\")\n","spacy_eng = spacy.load(\"en_core_web_sm\")\n","\n","\n","def tokenize_ger(text):\n","    return [tok.text for tok in spacy_ger.tokenizer(text)]\n","\n","def tokenize_eng(text):\n","    return [tok.text for tok in spacy_eng.tokenizer(text)]\n","\n","\n","german = Field(tokenize=tokenize_ger, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\")\n","\n","english = Field(\n","    tokenize=tokenize_eng, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\"\n",")\n","\n","train_data, valid_data, test_data = Multi30k.splits(\n","    exts=(\".de\", \".en\"), fields=(german, english)\n",")\n","# train_data, valid_data, test_data = Multi30k(language_pair=(\"de\", \"en\"))\n","\n","german.build_vocab(train_data, max_size=10000, min_freq=2)\n","english.build_vocab(train_data, max_size=10000, min_freq=2)\n","\n","\n","class Transformer(nn.Module):\n","    def __init__(\n","        self,\n","        embedding_size,\n","        src_vocab_size,\n","        trg_vocab_size,\n","        src_pad_idx,\n","        num_heads,\n","        num_encoder_layers,\n","        num_decoder_layers,\n","        forward_expansion,\n","        dropout,\n","        max_len,\n","        device,\n","    ):\n","        super(Transformer, self).__init__()\n","        self.src_word_embedding = nn.Embedding(src_vocab_size, embedding_size)\n","        self.src_position_embedding = nn.Embedding(max_len, embedding_size)\n","        self.trg_word_embedding = nn.Embedding(trg_vocab_size, embedding_size)\n","        self.trg_position_embedding = nn.Embedding(max_len, embedding_size)\n","\n","        self.device = device\n","        self.transformer = nn.Transformer(\n","            embedding_size,\n","            num_heads,\n","            num_encoder_layers,\n","            num_decoder_layers,\n","            forward_expansion,\n","            dropout,\n","        )\n","        self.fc_out = nn.Linear(embedding_size, trg_vocab_size)\n","        self.dropout = nn.Dropout(dropout)\n","        self.src_pad_idx = src_pad_idx\n","\n","    def make_src_mask(self, src):\n","        src_mask = src.transpose(0, 1) == self.src_pad_idx\n","\n","        # (N, src_len)\n","        return src_mask.to(self.device)\n","\n","    def forward(self, src, trg):\n","        src_seq_length, N = src.shape\n","        trg_seq_length, N = trg.shape\n","\n","        src_positions = (\n","            torch.arange(0, src_seq_length)\n","            .unsqueeze(1)\n","            .expand(src_seq_length, N)\n","            .to(self.device)\n","        )\n","\n","        trg_positions = (\n","            torch.arange(0, trg_seq_length)\n","            .unsqueeze(1)\n","            .expand(trg_seq_length, N)\n","            .to(self.device)\n","        )\n","\n","        embed_src = self.dropout(\n","            (self.src_word_embedding(src) + self.src_position_embedding(src_positions))\n","        )\n","        embed_trg = self.dropout(\n","            (self.trg_word_embedding(trg) + self.trg_position_embedding(trg_positions))\n","        )\n","\n","        src_padding_mask = self.make_src_mask(src)\n","        trg_mask = self.transformer.generate_square_subsequent_mask(trg_seq_length).to(\n","            self.device\n","        )\n","\n","        out = self.transformer(\n","            embed_src,\n","            embed_trg,\n","            src_key_padding_mask=src_padding_mask,\n","            tgt_mask=trg_mask,\n","        )\n","        out = self.fc_out(out)\n","        return out\n","\n","\n","# We're ready to define everything we need for training our Seq2Seq model\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","load_model = True\n","save_model = True\n","\n","# Training hyperparameters\n","num_epochs = 10\n","learning_rate = 3e-4\n","batch_size = 32\n","\n","# Model hyperparameters\n","src_vocab_size = len(german.vocab)\n","trg_vocab_size = len(english.vocab)\n","embedding_size = 512\n","num_heads = 8\n","num_encoder_layers = 3\n","num_decoder_layers = 3\n","dropout = 0.10\n","max_len = 100\n","forward_expansion = 4\n","src_pad_idx = english.vocab.stoi[\"<pad>\"]\n","\n","# Tensorboard to get nice loss plot\n","writer = SummaryWriter(\"runs/loss_plot\")\n","step = 0"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-09-14T05:19:50.239593Z","start_time":"2022-09-14T05:19:50.237442Z"},"id":"ARyGw4l7c_UY"},"outputs":[],"source":["train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n","    (train_data, valid_data, test_data),\n","    batch_size=batch_size,\n","    sort_within_batch=True,\n","    sort_key=lambda x: len(x.src),\n","    device=device,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-09-14T05:19:54.131063Z","start_time":"2022-09-14T05:19:50.240792Z"},"id":"fHosatc5c_UY"},"outputs":[],"source":["model = Transformer(\n","    embedding_size,\n","    src_vocab_size,\n","    trg_vocab_size,\n","    src_pad_idx,\n","    num_heads,\n","    num_encoder_layers,\n","    num_decoder_layers,\n","    forward_expansion,\n","    dropout,\n","    max_len,\n","    device,\n",").to(device)\n","\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n","    optimizer, factor=0.1, patience=10, verbose=True\n",")\n","\n","pad_idx = english.vocab.stoi[\"<pad>\"]\n","criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"start_time":"2022-09-14T05:19:25.924Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":444869,"status":"ok","timestamp":1630041413484,"user":{"displayName":"조영성","photoUrl":"","userId":"06200809104620413861"},"user_tz":-540},"outputId":"2faf0de6-405c-4c32-bba5-6629b051377a","id":"VVyczUt3c_UZ"},"outputs":[{"name":"stdout","output_type":"stream","text":["[Epoch 10 / 100]\n","=> Saving checkpoint\n","Translated example sentence: \n"," ['spend', 'sweaters', 'bottle', 'bottle', 'curious', 'member', 'sweaters', 'nike', 'sweaters', 'bottle', 'trucks', 'wading', 'bucks', 'than', 'bottle', 'sweaters', 'bottle', 'farmer', 'bottle', 'curious', 'moving', 'than', 'bottle', 'trucks', 'bottle', 'bottle', 'bottle', 'trucks', 'sweaters', 'bottle', 'reindeer', 'bottle', 'stunt', 'trucks', 'bottle', 'trucks', 'sweaters', 'bottle', 'bottle', 'bottle', 'bottle', 'trucks', 'bottle', 'trucks', 'bottle', 'bottle', 'trucks', 'sweaters', 'bottle', 'bottle']\n","[Epoch 11 / 100]\n","=> Saving checkpoint\n","Translated example sentence: \n"," ['a', 'horse', 'walks', 'under', 'a', 'bridge', 'next', 'to', 'a', 'boat', '.', '<eos>']\n","[Epoch 12 / 100]\n","=> Saving checkpoint\n","Translated example sentence: \n"," ['a', 'horse', 'walks', 'under', 'a', 'bridge', 'next', 'to', 'a', 'boat', '.', '<eos>']\n","[Epoch 13 / 100]\n","=> Saving checkpoint\n","Translated example sentence: \n"," ['a', 'horse', 'walks', 'under', 'a', 'bridge', 'next', 'to', 'a', 'boat', '.', '<eos>']\n","[Epoch 14 / 100]\n","=> Saving checkpoint\n","Translated example sentence: \n"," ['a', 'horse', 'walks', 'under', 'a', 'bridge', 'next', 'to', 'a', 'boat', '.', '<eos>']\n","[Epoch 15 / 100]\n","=> Saving checkpoint\n","Translated example sentence: \n"," ['a', 'horse', 'is', 'walking', 'under', 'a', 'bridge', 'under', 'a', 'boat', '.', '<eos>']\n","[Epoch 16 / 100]\n","=> Saving checkpoint\n","Translated example sentence: \n"," ['a', 'horse', 'is', 'walking', 'under', 'a', 'bridge', 'next', 'to', 'a', 'boat', '.', '<eos>']\n","[Epoch 17 / 100]\n","=> Saving checkpoint\n","Translated example sentence: \n"," ['a', 'horse', 'is', 'walking', 'under', 'a', 'boat', 'under', 'a', 'boat', '.', '<eos>']\n","[Epoch 18 / 100]\n","=> Saving checkpoint\n","Translated example sentence: \n"," ['a', 'horse', 'is', 'walking', 'next', 'to', 'a', 'boat', 'under', 'a', 'boat', '.', '<eos>']\n"]}],"source":["# if load_model:\n","#     load_checkpoint(torch.load(\"my_checkpoint.pth.tar\"), model, optimizer)\n","\n","sentence = \"ein pferd geht unter einer brücke neben einem boot.\"\n","# -> english: A horse walks under a bridge next to a boat.\n","num_epochs = 100\n","for epoch in range(10, num_epochs):\n","    print(f\"[Epoch {epoch} / {num_epochs}]\")\n","\n","    if save_model:\n","        checkpoint = {\n","            \"state_dict\": model.state_dict(),\n","            \"optimizer\": optimizer.state_dict(),\n","        }\n","        save_checkpoint(checkpoint)\n","\n","    model.eval()\n","    translated_sentence = translate_sentence(\n","        model, sentence, german, english, device, max_length=50\n","    )\n","\n","    print(f\"Translated example sentence: \\n {translated_sentence}\")\n","    model.train()\n","    losses = []\n","\n","    for batch_idx, batch in enumerate(train_iterator):\n","        # Get input and targets and get to cuda\n","        inp_data = batch.src.to(device)\n","        target = batch.trg.to(device)\n","\n","        # Forward prop\n","        output = model(inp_data, target[:-1, :])\n","\n","        output = output.reshape(-1, output.shape[2])\n","        target = target[1:].reshape(-1)\n","\n","        optimizer.zero_grad()\n","\n","        loss = criterion(output, target)\n","        losses.append(loss.item())\n","\n","        # Back prop\n","        loss.backward()\n","\n","        # Clip to avoid exploding gradient issues, makes sure grads are\n","        # within a healthy range\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n","\n","        # Gradient descent step\n","        optimizer.step()\n","\n","        # plot to tensorboard\n","        writer.add_scalar(\"Training loss\", loss, global_step=step)\n","        step += 1\n","\n","    mean_loss = sum(losses) / len(losses)\n","    scheduler.step(mean_loss)\n","\n","# running on entire test data takes a while\n","score = bleu(test_data[1:100], model, german, english, device)\n","print(f\"Bleu score {score * 100:.2f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"start_time":"2022-09-14T05:19:25.924Z"},"id":"UWzwVu2YB94b","scrolled":true},"outputs":[],"source":["model.eval()\n","sentence = \"Ich gehe zur Schule.\" # -> english: I go to school.\n","translated_sentence = translate_sentence(model, sentence, german, english, device, max_length=50)\n","print(translated_sentence)"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"start_time":"2022-09-14T05:19:25.925Z"},"colab":{"base_uri":"https://localhost:8080/","height":820},"executionInfo":{"elapsed":3742,"status":"ok","timestamp":1630041417219,"user":{"displayName":"조영성","photoUrl":"","userId":"06200809104620413861"},"user_tz":-540},"id":"fHgIIY-hd42a","outputId":"f64c3c36-43df-40c4-8e1c-04d2bfb8fc8e"},"outputs":[],"source":["%load_ext tensorboard\n","%tensorboard --logdir runs/loss_plot --bind_all"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Aag8FYtZc_Ub"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[]},"hide_input":false,"kernelspec":{"display_name":"torch112","language":"python","name":"torch112"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"nbformat":4,"nbformat_minor":0}